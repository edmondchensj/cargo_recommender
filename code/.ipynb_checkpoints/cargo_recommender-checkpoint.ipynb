{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O-D Cities Recommender System\n",
    "This notebook proposes a method to recommend Origin-Destination city routes for cargo drivers. \n",
    "\n",
    "## Table of Contents:\n",
    "* 1 Introduction\n",
    "    * Background\n",
    "    * Method\n",
    "    * Data\n",
    "    * Summary of Results\n",
    "* 2 Code\n",
    "    * Load Data\n",
    "    * Preprocess\n",
    "    * {Checkpoint}\n",
    "    * Build Model\n",
    "    * Validate\n",
    "* 3 Conclusion\n",
    "* 4 Appendix\n",
    "\n",
    "# 1 Introduction\n",
    "## Background\n",
    "A goal of our research group has been to identify cargo-delivery routes. By identifying cargo-delivery routes, we would be able to do higher-order analysis on driver behaviors such as route predictions. \n",
    "\n",
    "An approach I thought of is to predict a driver's **preferred** origin-destination (O-D) cities routes. While we lack ground-truth on the specific cargo routes, we may be able to detect the city-city preferences of drivers using the company's \"active\" cargo data.\n",
    "\n",
    "The approach is similar to recommender systems carried out by social media platforms such as Netflix. \n",
    "\n",
    "\n",
    "## Method\n",
    "The Recommender System approach used here is **Collaborative Filtering**, which has been commonly used by social media platforms. The specific algorithm is a form of **Matrix Factorization**, which is the **model-based implementation** of Collaborative Filtering. The algorithm is based on the paper titled [Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf) by Hu et al. (2008). \n",
    "\n",
    "To implement this algorithm, I used the python library [*implicit*](https://github.com/benfred/implicit).  \n",
    "\n",
    "\n",
    "## Data\n",
    "The data used was dr250_active.csv.\n",
    "\n",
    "\n",
    "## Summary of Results\n",
    "Definitions:\n",
    "* N: number of OD pairs recommended to each user,\n",
    "* k: number of OD pairs in the test set for each user.\n",
    "\n",
    "Using parameters N=100 and k=20, the Collaborative Filtering model scored, using [*recall*](https://en.wikipedia.org/wiki/Precision_and_recall): **~20%**. \n",
    "\n",
    "This is compared to the benchmark score of **~0.6%**, based on recommending the same set of top N most popular items to every user.\n",
    "\n",
    "-----\n",
    "\n",
    "# 2 Code\n",
    "Below shows the code and relevant output. The helper script cargo_recommender.py is uploaded in the Google Drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "import time\n",
    "from cargo_recommender import (get_user_item_matrix,\n",
    "                               train_test_split,\n",
    "                               validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime     userid acttype orgprov orgcity destprov destcity  \\\n",
      "0  2018-03-06 00:42:41  1_1009235  search  yunnan    yuxi      NaN      NaN   \n",
      "1  2018-03-06 00:42:41  1_1009235  search  yunnan    yuxi      NaN      NaN   \n",
      "2  2018-03-06 00:42:41  1_1009235  search  yunnan    yuxi      NaN      NaN   \n",
      "3  2018-03-06 00:42:41  1_1009235  search  yunnan    yuxi      NaN      NaN   \n",
      "4  2018-03-06 00:42:41  1_1009235  search  yunnan    yuxi      NaN      NaN   \n",
      "\n",
      "   trucktype  trucklen       orderid  \n",
      "0         -1        -1  8.379983e+09  \n",
      "1         -1        -1  8.383683e+09  \n",
      "2         -1        -1  8.374969e+09  \n",
      "3         -1        -1  8.385825e+09  \n",
      "4         -1        -1  8.385566e+09  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dr250_active.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "The data is split to train and test using a form of \"leave-k-out\" approach. \n",
    "The procedure is:\n",
    "1. Split users to train and test sets. \n",
    "(Additional requirement for users in test set: must have at least k*10 unique O-D pairs.)\n",
    "2. For each user in test set, remove k items out of the train set and place in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to preprocess data: 0.35s\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "user_items = get_user_item_matrix(df)\n",
    "k = 20\n",
    "user_items_train, test_users = train_test_split(user_items,\n",
    "                                               split_method='leave_k_out',\n",
    "                                               k=k)\n",
    "print(f'Time taken to preprocess data: {time.time()-s:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {Checkpoint}\n",
    "Before we build the model, let's examine a few key statistics.\n",
    "1. Number of unique O-D pairs.\n",
    "2. Number of unique O-D pairs per user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "The model is built using the [implicit](https://github.com/benfred/implicit) library. The algorithm is based on the paper [Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf) by Hu et al (2008). The parameters can be tuned further to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30.0/30 [00:01<00:00, 28.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to build model: 1.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "model = implicit.als.AlternatingLeastSquares(factors=10,\n",
    "                                            regularization=0.1,\n",
    "                                            iterations=30)\n",
    "alpha=2\n",
    "item_users_train = user_items_train.transpose()\n",
    "model.fit(item_users_train*alpha)\n",
    "print(f'Time taken to build model: {time.time()-s:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate\n",
    "The accuracy was calculated using recall metrics. The formula is, for each user in test set:\n",
    "    \n",
    "    (# items in predictions AND test set) / (# items in test set)\n",
    "    \n",
    "The accuracy was averaged across all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (Recall)\n",
      "----------\n",
      "Model: 16.765%\n",
      "Benchmark: 0.686%\n",
      "[Benchmark based on recommending the top N most popular O-D routes to every user. N = 100]\n",
      "\n",
      "Time taken to validate model: 0.09s\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "N = 100\n",
    "validate(model,user_items,user_items_train,test_users,N=N)\n",
    "print(f'\\nTime taken to validate model: {time.time()-s:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# 3 Conclusion\n",
    "The accuracy based on recall is shown above at around 17%. This is not high, presumably because of the high number of unique O-D combinations in the data. Compared to the benchmark however, it has a significant improvement. \n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "# 4 Appendix\n",
    "\n",
    "## Further Reading.\n",
    "The code was adapted from the following two blogs:\n",
    "* https://towardsdatascience.com/recommending-github-repositories-with-google-bigquery-and-the-implicit-library-e6cce666c77\n",
    "* https://jessesw.com/Rec-System/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
